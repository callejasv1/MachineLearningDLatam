{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba 1: Análisis de Sentimientos de Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presenta un problema clásico en el análisis de texto: Extraer el sentimiento asociado a un texto. \n",
    "\n",
    "Para esto, utilizaremos una base de datos provenientes de CrowdFlower. \n",
    "\n",
    "Para descargar los datos puede ejecutar el siguiente código:\n",
    "wget https://www.crowdflower.com/wp-content/uploads/2016/07/text_emotion.csv \n",
    "\n",
    "El objetivo general de esta prueba es alcanzar el mejor desempeño posible para clasificar si un tweet es positivo o negativo.\n",
    "Para medir el desempeño, se evaluará con un conjunto de datos del cuál no tendrán acceso. De esta manera evitaremos que los modelos aprendan información sobre el conjunto de validación.\n",
    "Crea una carpeta de trabajo y guarda todos los archivos correspondientes (notebook, archivos auxiliares y csv).\n",
    "Una vez terminada la prueba, comprime la carpeta y sube el .zip a la sección correspondiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para alcanzar el objetivo general, su trabajo se puede desagregar en los siguientes puntos:\n",
    "1. Generar un análisis exploratorio sobre los datos contenidos en el DataFrame, considerando palabras más comunes y distribución de las clases en el vector objetivo.\n",
    "2. Preprocesamiento de Texto:\n",
    "Para trabajar adecuadamente con texto, debemos preprocesar y posteriormente representar cada oración como un conjunto de características.\n",
    "Para preprocesar los tweets, debemos transformarlos a lower case. Un problema recurrente en el análisis de texto es la alta ocurrencia de palabras comunes.\n",
    " - Se recomienda eliminarlas mediante la declaración de stopwords. Para generar la exclusión de stopwords, podemos utilizar la librería nltk (Natural Language ToolKit) y descargar los stopwords con la siguiente instrucción.\n",
    " \n",
    "    - Puede refinar los atributos a capturar mediante el proceso de lemantización (la reducción de variadas palabras con un tronco léxico común; ejemplo: Organización, Organiza, y Organizado presentan organi_ como tronco léxico en comúmn) o Stemming (la reducción de una palabra a una expresión generalizable). Cabe destacar que ésta última carece de análisis morfológico del lenguaje. \n",
    "\n",
    "    - Posterior a la refinación y preprocesamiento de las palabras, podemos representar cada oración en una matriz (o corpus) que permitirá reflejar la cantidad de ocurrencias de palabra en un registro. Para ello, pueden hacer uso de las librerías de preprocesamiento sklearn.feature_extraction.text.CountVectorizer o sklearn.feature_extraction.text.TfidfVectorizer . \n",
    "    - De esta manera, tendremos un conjunto de características es mediante la frecuencia de ocurrencia de una palabra o término en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/eduardo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "rep_seed = 3504\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "import lec10_graphs as afx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Preparación del vector objetivo y las matrices de entrenamiento y validación:\n",
    "Nos interesa trabajar con dos tipos de emociones: positivas o negativas. Para ello deberá generar la recodificación de cada una de las clases en una de las dos emociones:\n",
    "        \n",
    "Original | Recodificación\n",
    "---|---\n",
    "'worry' | Negativa\n",
    "'happiness' | Positiva\n",
    "'sadness' | Negativa\n",
    "'love' | Positiva\n",
    "'surprise' | Positiva\n",
    "'fun' | Positiva\n",
    "'relief' | Positiva\n",
    "'hate' | Negativa\n",
    "'empty' | Negativa\n",
    "'enthusiasm' | Positiva\n",
    "'boredom' | Negativa\n",
    "'anger' | Negativa\n",
    " \n",
    " \n",
    " \n",
    "Si el tweet está asignado como neutral , clasifíquelo aleatoriamente entre positivo o negativo.\n",
    " \n",
    "4. Entrenamiento de modelos:\n",
    "En base a los modelos vistos en clase, implemente por lo menos 5. Para cada uno de ellos justifique la elección de hiperparámetros. Si implementa búsqueda de grilla para cada uno de ellos, defina el rango de valores a tomar en cada hiperparámetro.\n",
    "Reporte el desempeño de cada modelo en las muestras de entrenamiento y validación. Comente sobre la capacidad de generalización de cada uno de ellos haciendo uso de los conceptos vistos en el curso.\n",
    "5. Seleccione los 2 mejores modelos, serialicelos y envíelos a evaluación. Recuerde que el modelo serializado debe ser posterior al fit , para poder ejecutar predict en los nuevos datos.\n",
    "6. La evaluación del modelo será realizada en función a un conjunto de datos reservados al cual no tienen acceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación del espacio de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_tweets.csv').drop(columns='Unnamed: 0')\n",
    "positivos = {('happiness','love','surprise','fun','relief','hate','empty','enthusiasm','boredom'):1,('worry','sadness','hate','empty','boredom','anger'):0}\n",
    "list_positivos = ['happiness','love','surprise','fun','relief','hate','empty','enthusiasm','boredom']\n",
    "list_negativos = ['worry','sadness','hate','empty','boredom','anger']\n",
    "sentiments = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"sentiment!='neutral'\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment.replace(list_positivos, 1, inplace=True)\n",
    "df.sentiment.replace(list_negativos, 0, inplace=True)\n",
    "df['randNumCol'] = np.random.randint(0, 2, df.shape[0])\n",
    "df['sentiment_re'] = np.where(df['sentiment']=='neutral',df['randNumCol'],df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>randNumCol</th>\n",
       "      <th>sentiment_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy Mama's day to all mothers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@LysdelTellez I am lost. Please help me find a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@BoomKatt yes yes I AM, networking whore to th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>now i am doing the MicroEconomics project  iha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@jackEO313 at first i thought bar life meant y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  sentiment  randNumCol  \\\n",
       "0                    Happy Mama's day to all mothers          1           0   \n",
       "1  @LysdelTellez I am lost. Please help me find a...          0           1   \n",
       "2  @BoomKatt yes yes I AM, networking whore to th...          1           0   \n",
       "4  now i am doing the MicroEconomics project  iha...          0           1   \n",
       "6  @jackEO313 at first i thought bar life meant y...          1           1   \n",
       "\n",
       "   sentiment_re  \n",
       "0             1  \n",
       "1             0  \n",
       "2             1  \n",
       "4             0  \n",
       "6             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_strings(string_array):\n",
    "    # ingresamos stopwords y stemmer\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    # con el stemmer reducimos las palabras a una raíz semántica común.\n",
    "    stemmer = nltk.stem.snowball.SnowballStemmer(\"english\")\n",
    "    # holder de strings a nivel de array\n",
    "    string_array_holder = []\n",
    "    # por cada string en el array\n",
    "    for string in string_array:\n",
    "        # holder de palabras en cada string\n",
    "        string_holder = []\n",
    "        # separamos (tokenizamos) cada palabra en el string\n",
    "        tokenized_strings = nltk.word_tokenize(string)\n",
    "        # por cada palabra en el string\n",
    "        for token in tokenized_strings:\n",
    "            # lowercase\n",
    "            token = token.lower()\n",
    "            # reemplazamos todo caracter noalfanumérico a nada.\n",
    "            token = re.sub(re.compile(\"[^A-Za-z0-9]+\"), \"\", token)\n",
    "            # si la palabra no es vacía y no se encuentra a nivel de stopwords\n",
    "            if token != \"\" and token not in stopwords:\n",
    "                # reducimos a la raíz semántica\n",
    "                token = stemmer.stem(token)\n",
    "            # si es que es válida\n",
    "            if token != \"\":\n",
    "                # concatenamos\n",
    "                string_holder.append(token)\n",
    "        # concatenamos a nivel de holders\n",
    "        string_array_holder.append(string_holder)\n",
    "    # devolvemos\n",
    "    \n",
    "    return string_array_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = preprocess_strings(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23549"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23549 entries, 0 to 23548\n",
      "Data columns (total 1 columns):\n",
      "0    23549 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 184.1+ KB\n"
     ]
    }
   ],
   "source": [
    "emptydf = []\n",
    "for i in stem:\n",
    "    a=' '.join(i)\n",
    "    emptydf.append(a)\n",
    "lemm = pd.DataFrame(emptydf)\n",
    "lemm.info()\n",
    "df.reset_index(inplace=True)\n",
    "df['content']=lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_re'] = df['sentiment_re'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23549 entries, 0 to 23548\n",
      "Data columns (total 5 columns):\n",
      "index           23549 non-null int64\n",
      "content         23549 non-null object\n",
      "sentiment       23549 non-null int64\n",
      "randNumCol      23549 non-null int64\n",
      "sentiment_re    23549 non-null int64\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 920.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_re'].value_counts()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23549 entries, 0 to 23548\n",
      "Data columns (total 5 columns):\n",
      "index           23549 non-null int64\n",
      "content         23549 non-null object\n",
      "sentiment       23549 non-null int64\n",
      "randNumCol      23549 non-null int64\n",
      "sentiment_re    23549 non-null int64\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x106755f60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df, x='sentiment',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el problema como un problema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las clases estan relativamente balanceadas, de todas formas para evitar distorsiones en la métrica, utilizaremos F1-macro para encontrar una métrica que mida ambas clases con igual peso ambas, dado que no conocemos el *problema de negocio* y si alguna de estas métricas es mas importante que la otra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english',max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fit = cv.fit_transform(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23549x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 114392 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = cv_fit.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.DataFrame(word_freq,columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_cv,\n",
    "                                                  df['sentiment_re'],\n",
    "                                                  test_size=.33,\n",
    "                                                  random_state=3504)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      3392\n",
      "           1       0.72      0.75      0.73      4380\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      7772\n",
      "   macro avg       0.69      0.69      0.69      7772\n",
      "weighted avg       0.69      0.70      0.69      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_hat = NB.predict(X_test)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=3540, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=3540, penalty='l2')\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63      3392\n",
      "           1       0.71      0.78      0.74      4380\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      7772\n",
      "   macro avg       0.69      0.69      0.69      7772\n",
      "weighted avg       0.70      0.70      0.70      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos GridSearch para optimizar los hiperparámtros de la regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=3504, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]), 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression(random_state=3504, fit_intercept=False)\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=5, scoring='f1', n_jobs=-1)\n",
    "logreg_cv.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      3392\n",
      "           1       0.73      0.75      0.74      4380\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      7772\n",
      "   macro avg       0.70      0.70      0.70      7772\n",
      "weighted avg       0.70      0.70      0.70      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = logreg_cv.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Arbol de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58      3392\n",
      "           1       0.68      0.66      0.67      4380\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      7772\n",
      "   macro avg       0.62      0.63      0.62      7772\n",
      "weighted avg       0.63      0.63      0.63      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = dtc.predict(X_test)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dec_tree_grid_cv = pickle.load(open('dec_tree_grid_cv.sav','rb'))\n",
    "except:\n",
    "\n",
    "    dec_tree_grid_cv = GridSearchCV(DecisionTreeClassifier(),\n",
    "                                        # evaluamos 10 escenarios\n",
    "                                       {'min_samples_split': np.linspace(0.1, 1.0, 10),\n",
    "                                        # implementando 2 criterios de partición\n",
    "                                        'criterion': ['gini', 'entropy'],\n",
    "                                        # con una profundidad de ramas hasta 5\n",
    "                                       'max_depth': np.linspace(1, 5, 5),\n",
    "                                        # evaluando 10 escenarios\n",
    "                                       'min_samples_leaf': np.linspace(0.1, 0.5, 10)},\n",
    "                                    # Con 3 validaciones cruzadas\n",
    "                                    cv=3,\n",
    "                                    # Ocupando todos los núcleos del computador\n",
    "                                    n_jobs=-1, scoring='f1-macro').fit(X_train, y_train)\n",
    "\n",
    "    pickle.dump(dec_tree_grid_cv, open('dec_tree_grid_cv.sav','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 1.0,\n",
       " 'min_samples_leaf': 0.1,\n",
       " 'min_samples_split': 0.1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3392\n",
      "           1       0.56      1.00      0.72      4380\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      7772\n",
      "   macro avg       0.28      0.50      0.36      7772\n",
      "weighted avg       0.32      0.56      0.41      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = dec_tree_grid_cv.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_rf = RandomForestClassifier(oob_score=True, random_state=11238).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      3392\n",
      "           1       0.70      0.69      0.69      4380\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      7772\n",
      "   macro avg       0.65      0.65      0.65      7772\n",
      "weighted avg       0.66      0.66      0.66      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, voting_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_stump = DecisionTreeClassifier(max_depth=5, random_state=11238).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_classifier = AdaBoostClassifier(base_estimator=logreg_cv.best_estimator_, random_state=3504).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.47      0.55      3392\n",
      "           1       0.66      0.82      0.73      4380\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      7772\n",
      "   macro avg       0.66      0.64      0.64      7772\n",
      "weighted avg       0.66      0.66      0.65      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, adaboost_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el comité de clasificadores en una lista de tuplas\n",
    "\n",
    "\n",
    "estimators3 = [('Linear Discriminant Analysis', LinearDiscriminantAnalysis()),\n",
    "              ('Logistic Regression', LogisticRegression(random_state=rep_seed,fit_intercept=False)),\n",
    "              \n",
    "              ('Naive Bayes', BernoulliNB())\n",
    "             ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index, value in enumerate(estimators3):\n",
    "    plt.subplot(3, 2,  index + 1)\n",
    "    plt.title(value[0])\n",
    "    class_pred = value[1].fit(X_train, y_train).predict(X_test)\n",
    "    afx.plot_classification_report(y_test, class_pred)\n",
    "    plt.axvline(.5, label='.5 Boundary', linestyle='--')\n",
    "    plt.xlim((0.1, 1.0))\n",
    "    if (index + 1) % 2 == 0:\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos una función que nos permite buscar cual es el mejor f-1 macro de una combinación de pesos, de forma de elegir el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.694561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.694544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.693705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.693607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.693398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.693304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.693297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.693235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.693167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.692809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.692717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.692047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.691789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.691648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.691448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.691268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.691202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.691071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.691027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.690977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.690929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.690104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.689823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w1   w2   w3        f1\n",
       "3   1.0  2.0  2.0  0.694561\n",
       "1   1.0  1.0  3.0  0.694544\n",
       "4   1.0  2.0  3.0  0.693705\n",
       "9   2.0  1.0  2.0  0.693607\n",
       "10  2.0  1.0  3.0  0.693398\n",
       "15  2.0  3.0  3.0  0.693304\n",
       "7   1.0  3.0  3.0  0.693297\n",
       "21  3.0  2.0  3.0  0.693235\n",
       "0   1.0  1.0  2.0  0.693167\n",
       "6   1.0  3.0  2.0  0.692809\n",
       "14  2.0  3.0  2.0  0.692717\n",
       "5   1.0  3.0  1.0  0.692070\n",
       "18  3.0  1.0  3.0  0.692047\n",
       "12  2.0  2.0  3.0  0.691789\n",
       "8   2.0  1.0  1.0  0.691648\n",
       "2   1.0  2.0  1.0  0.691448\n",
       "20  3.0  2.0  2.0  0.691268\n",
       "23  3.0  3.0  2.0  0.691202\n",
       "16  3.0  1.0  1.0  0.691071\n",
       "17  3.0  1.0  2.0  0.691027\n",
       "13  2.0  3.0  1.0  0.690977\n",
       "19  3.0  2.0  1.0  0.690929\n",
       "11  2.0  2.0  1.0  0.690104\n",
       "22  3.0  3.0  1.0  0.689823"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_n = pd.DataFrame(columns=('w1', 'w2', 'w3', 'f1'))\n",
    "\n",
    "i = 0\n",
    "for w1 in range(1,4):\n",
    "    for w2 in range(1,4):\n",
    "        for w3 in range(1,4):\n",
    "\n",
    "            if len(set((w1,w2,w3))) == 1: # skip if all weights are equal\n",
    "                continue\n",
    "            voting_classifier = VotingClassifier(estimators3,voting='soft',weights=(w1,w2,w3)).fit(X_train, y_train)\n",
    "            #print((w1,w2,w3))\n",
    "            #print(classification_report(y_test, voting_classifier.predict(X_test)))\n",
    "            \n",
    "            df_l = pd.DataFrame(classification_report(y_test, voting_classifier.predict(X_test), output_dict=True))\n",
    "            df_l.ix[0,3]\n",
    "            df_n.loc[i] = [w1, w2, w3, df_l.ix[0,3]]\n",
    "            i += 1\n",
    "df_n.sort_values(by='f1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier(estimators3,voting='soft',weights=[1,2,2]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      3392\n",
      "           1       0.72      0.76      0.74      4380\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      7772\n",
      "   macro avg       0.70      0.69      0.69      7772\n",
      "weighted avg       0.70      0.70      0.70      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, voting_classifier.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los dos mejores modelos son la regresión logistica, y el voting classifier. Serializamos ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecallejas_modelo_1 = pickle.dump(logreg_cv.best_estimator_, open('ecallejas-modelo-1','wb')) # Regresion Log\n",
    "ecallejas_modelo_2 = pickle.dump(voting_classifier, open('ecallejas-modelo-2','wb')) # Voting classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra... Que sucede si utilizamos PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X= df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23549 entries, 0 to 23548\n",
      "Columns: 101 entries, 0 to sentiment_re\n",
      "dtypes: float64(100), int64(1)\n",
      "memory usage: 18.1 MB\n"
     ]
    }
   ],
   "source": [
    "finalDf = pd.concat([principalDf, df['sentiment_re']], axis = 1)\n",
    "finalDf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(principalDf,\n",
    "                                                  df['sentiment_re'],\n",
    "                                                  test_size=.33,\n",
    "                                                  random_state=3504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58      3392\n",
      "           1       0.68      0.80      0.73      4380\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      7772\n",
      "   macro avg       0.67      0.66      0.66      7772\n",
      "weighted avg       0.67      0.67      0.67      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_classifier = AdaBoostClassifier(base_estimator=lr, random_state=11238).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.31      0.43      3392\n",
      "           1       0.63      0.90      0.74      4380\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      7772\n",
      "   macro avg       0.66      0.60      0.58      7772\n",
      "weighted avg       0.66      0.64      0.60      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, adaboost_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el comité de clasificadores en una lista de tuplas\n",
    "estimators = [('Linear Discriminant Analysis', LinearDiscriminantAnalysis()),\n",
    "              ('Logistic Regression', LogisticRegression(random_state=rep_seed)),\n",
    "               ('Adaboost Classifier', AdaBoostClassifier(base_estimator=lr, random_state=rep_seed))\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57      3392\n",
      "           1       0.67      0.81      0.73      4380\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      7772\n",
      "   macro avg       0.67      0.65      0.65      7772\n",
      "weighted avg       0.67      0.67      0.66      7772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators, voting='soft').fit(X_train, y_train)\n",
    "print(classification_report(y_test, voting_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticGAM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-7320e7b6be93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlgam\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mLogisticGAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlgam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticGAM' is not defined"
     ]
    }
   ],
   "source": [
    "lgam =LogisticGAM()\n",
    "\n",
    "\n",
    "lgam.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lgam.predict(X_test)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obtenemos mejores resultados, pero tampoco decaen tanto, es interesante ver que si el tiempo de entrenamiento fuese una variable importante dentro de la elección del modelo, al disminuir los atributos a 100, podemos aplicar modelos que de otra forma se demorarían mucho. (Por ejemplo Logistic Gam, redes neuronales o GridSearch con muchas variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
