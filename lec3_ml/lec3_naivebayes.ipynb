{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](logo.png)\n",
    "\n",
    "\n",
    "# Bayes Ingenuo\n",
    "\n",
    "> __Alcance de la lectura__\n",
    "> * Identificar los componentes del Teorema de Bayes\n",
    "> * Reconocer el problema de probabilidad inversa y su solución con Bayes Ingenuo\n",
    "> * Reconocer las diferentes formas de Bayes Ingenuo\n",
    "> * Implementar algoritmos de Bayes Ingenuo con `sklearn`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Motivación\n",
    "\n",
    "\n",
    "A lo largo de esta lectura trabajaremos con el algoritmo Bayes Ingenuo, que permite desarrollar un modelo predictivo relativamente eficaz para lo simple de su implementación. Este algoritmo pertenece a la familia de los clasificadores __generativos__: aquellos que aprenden características de un modelo a partir de la probabilidad conjunta $\\textsf{Pr}(x, y) $entre atributos $x \\in \\mathbf{X}^{\\mathbb{R}}$ y un espacio finito de clases $y \\in \\mathbb{Y}$ para asignar clases a observaciones en base a $\\textsf{Pr}(y\\vert x)$ mediante el Teorema de Bayes. En la otra vereda se encuentran los clasificadores __discriminativos__: aquellos que aprenden las clases $\\textsf{Pr}(y\\vert x)$ de forma directa mediante una función objetivo de $\\mathbf{X}$ a $y$. Para más detalles entre la relación de clasificadores generativos y discriminativos, pueden leer Ng y Jordan (2001).\n",
    "\n",
    "Para ejemplificar esto trabajaremos con una base de datos sobre admisiones a la Universidad de California, Berkeley. En base a dos atributos (género y departamento de los postulantes), desarrollaremos un modelo Bayes Ingenuo Bernoulli para predicir de forma correcta aquellos casos que fueron admitidos. \n",
    "\n",
    "\n",
    "## Précis: Probabilidad Inversa mediante el Teorema de Bayes\n",
    "\n",
    "\n",
    "El algoritmo Bayesiano Ingenuo tiene sus fundamentos en el Teorema de Bayes. Éste teorema gravita alrededor de la _probabilidad condicional_ (la probabilidad que un evento $A$ ocurra __condicional a la ocurrencia__ de otro evento $B$). Lo que busca el Teorema de Bayes es analizar la probabilidad del evento condicionante $B$, dado que ocurre el evento $A$. Consideremos el siguiente ejemplo:\n",
    "\n",
    "_¿Qué pasa cuando una persona te sonríe cada vez que te ve? Esta es una de las incógnitas más grandes de la humanidad. Asumamos que sabemos que hay una probabilidad conjunta del 95% que cuando una persona le guste alguien, sonría. También sabemos que existe un 10% de probabilidad que le sonría a un extraño y un 1% que le guste alguien al azar. Podemos implementar el teorema de Bayes para encontrar una respuesta a este problema existencial._\n",
    "\n",
    "El mantra Bayesiano reza: __En el contexto del Teorema de Bayes, dice que la probabilidad _a posteriori_ es proporcional a la _verosimilitud_ por la probabilidad _a priori_, ajustada por la _evidencia_.__ La forma canónica del teorema se representa como :\n",
    "\n",
    "$$\n",
    "\\textsf{Pr}(\\text{A posteriori}) = \\frac{\\textsf{Pr}(\\text{Verosimilitud}) \\times \\textsf{Pr}(\\text{A priori})}{\\textsf{Pr}(\\text{Evidencia})}\n",
    "$$\n",
    "\n",
    "Identifiquemos y reemplacemos los componentes en nuestra ecuación:\n",
    "\n",
    "$$\n",
    "\\textsf{Pr}(\\text{Le gusto } \\vert \\text{ Me sonríe}) = \\frac{\\textsf{Pr}(\\text{Me sonríe } \\vert \\text{ Le gusto}) \\times \\textsf{Pr}(\\text{Le gusto})}{  \\textsf{Pr}(\\text{Sonríe})}\n",
    "$$\n",
    "\n",
    "* $\\textsf{Pr}(\\text{Le gusto} \\vert \\text{Me sonríe})$ = es la probabilidad que le gustes sabiendo que te sonríe cuando te ve. Este es nuestra incógnita a resolver\n",
    "* $\\textsf{Pr}(\\text{Me sonríe} \\vert \\text{Le gusto})$ = es la probabilidad que sonría asumiendo que le sonríe a la gente que le gusta. Esta es la información que asumimos, que hay una probabilidad del 95% que le sonría a las personas que le gusta.\n",
    "* $\\textsf{Pr}(\\text{Le gusto})$ = es la probabilidad que le guste una persona al azar. Sabemos que hay un 1% de chances que esa persona le guste alguien al azar.\n",
    "* $\\textsf{Pr}(\\text{Me sonríe})$ = es la probabilidad que le sonría a alguien al azar. Por último, tambien sabemos que hay un 10% de que esa persona sonría al azar a un extraño.\n",
    "\n",
    "Para facilitar el desarrollo de esta ecuación, la implementaremos en Python mediante una función:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_solver(likelihood = .95, prior = 0.01, evidence = 0.1):\n",
    "    return round(likelihood * prior / evidence, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con nuestra función, podemos averiguar la probabilidad a posteriori que le guste a alguien dado que me sonríe cada vez que me ve. Los resultados son desesperanzadores, tenemos un 9% de probabilidad que le gustemos a alguien dado que me sonríe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.095"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_solver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasaría si sabemos que esa persona tiende a sonreír a mucha más gente que el promedio? Asumamos que le sonríe al 20% de la gente que ve. Nuestras probabilidades son aún peores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_solver(evidence=.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También sabemos que ésta persona tiende a gustarle muchas personas. Le gusta alrededor del 20% de las personas que ve. Si actualizamos nuestra función con estos resultados, recuperamos nuestras esperanzas a que le gustamos! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_solver(prior=0.2, evidence=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejercicio anterior demuestra la principal virtud del paradigma bayesiano: __nos permite incorporar información adicional al análisis__. De no haber considerado las probabilides de sonreír y afectividad, probablemente hubiésemos pasado un mal rato.\n",
    "\n",
    "\n",
    "> __Digresión:__ Teorema de Bayes $\\neq$ Métodos Bayesianos\n",
    ">\n",
    "> Un aspecto a considerar cuando implementamos el Teorema de Bayes con el código de arriba, es que no tiene nada de bayesiano. McElreath (2016, pp.50) recalca el hecho que el teorema de Bayes hace uso de la frecuencia de los eventos ocurridos, a diferencia de los métodos bayesianos que utilizan parámetros que se asumen fijos pero inciertos.\n",
    ">\n",
    "> Mientras que el Teorema de Bayes permitió definir un marco esencialmente frecuentista para resolver la probabilidad condicional inversa, los métodos bayesianos buscan realizar inferencia sobre los parámetros __a posteriori__ en función a cómo la información __a priori__ afecta a una función de __verosimilitud__. La inferencia bayesiana tardó en desarrollarse, dado que muchos de los problemas llegaban a soluciones intratables. Resulta que el problema de la intratabilidad se podía solucionar mediante los métodos __Markov Chain Monte Carlo (MCMC)__, que permiten muestrear a partir de una distribución probabilística.\n",
    "> Esto queda más claro con la imagen de abajo, proveniente de _Kruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press._\n",
    ">\n",
    "> ![](bayesiandogos.png)\n",
    "> \n",
    "> La distribución _a posteriori_ ($\\textsf{Pr} (\\theta \\vert \\text{ Datos})$ representada con el Fox Terrier) es un compromiso entre la verosimilitud $(\\textsf{Pr}(\\text{ Datos} \\vert \\theta)$ representada con el Corgi) y la información _a priori_ de la verosimilitud $(\\textsf{Pr}(\\theta)$ representada con el Golden Retriever). Resulta que el Fox Terrier presenta orejas mitad caídas, representando el compromiso entre el Corgi y el Golden Retriever. Por último, el labrador $\\textsf{Pr}(\\text{Datos})$ está bostezando porque en los métodos MCMC la verosimilitud marginal de los datos importa poco.\n",
    "\n",
    "## Bayes Ingenuo\n",
    "\n",
    "Ya sabemos que el teorema de Bayes nos permite extraer la probabilidad inversa de un fenómeno mediante el ajuste de la verosimilitud de ocurrencia de un evento por la información previa existente. Una de las explicaciones más comunes del teorema de Bayes es lo que se conoce como el algoritmo Bayes Ingenuo, de aquí en adelante abreviado a __NB__ por su nombre en inglés, Naïve Bayes. En esta lectura implementaremos su versión más simple, el algoritmo NB Bernoulli, donde buscamos identificar la pertenencia de una observación a un conjunto finito de clases $y \\in \\mathbb{Y}$.\n",
    "\n",
    "El objetivo del algoritmo es identificar la pertenencia de una observación a una determinada clase, basándose en los atributos medidos. De esta forma buscamos maximizar el estimador _a posteriori_ de la fórmula de Bayes. Para obtener un estimador _map_ (máximo a posteriori) en base al Teorema de Bayes, lo implementamos mediante:\n",
    "\n",
    "$$\n",
    "\\textsf{Pr}(y\\vert X) \\propto \\textsf{Pr}(y) \\prod_{1 \\leq k \\leq n_{d}} \\textsf{Pr}(X_{k} \\vert y)\n",
    "$$\n",
    "\n",
    "donde $\\textsf{Pr}(X_{k} \\vert y)$ es la probabilidad condicional de ocurrencia del atributo $X_{k}$ en la clase $y \\in \\mathbb{Y}$, que representa la contribución del atributo en la clase (asumiendo que es la clase correcta). $\\textsf{Pr}(y)$ es la probabilidad previa de ocurrencia de la clase. Dado que no tenemos suficiente información como para asumir $\\textsf{Pr}$ como verdaderos, optamos por declarar sus estimados $\\hat{\\textsf{Pr}}$. Así, el problema de optimización es entrenar un modelo que maximize la clase más probable a ocurrir mediante la siguiente expresión: \n",
    "\n",
    "$$\n",
    "\\hat{y}_{\\text{map}} = \\underset{y\\in\\mathbb{Y}}{\\textsf{argmax  }} \\hat{\\textsf{Pr}} (y \\vert X) = \\underset{y\\in\\mathbb{Y}}{\\textsf{argmax  }} \\hat{\\textsf{Pr}(y)} \\prod_{1 \\leq k \\leq n_{d}} \\textsf{Pr}(X_{k} \\vert y)\n",
    "$$\n",
    "\n",
    "Dado que estamos multiplicando un número grande de probabilidades condicionales por cada atributo entre $1 \\leq k \\leq n_{d}$, un problema computacional recurrente es el _floating point underflow_. Una de las soluciones más comunes es trabajar con el logaritmo de esta expresión, quedando como:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{\\text{map}} = \\underset{y\\in\\mathbb{Y}}{\\textsf{argmax  }} \\Big[\\textsf{log }\\hat{\\textsf{Pr}}(y) + \\sum_{1 \\leq k \\leq n_{d}} \\textsf{log }\\hat{\\textsf{Pr}}(X_{k} \\vert y)\\Big]\n",
    "$$\n",
    "\n",
    "Los estimados de la probabilidad se obtienen a partir de:\n",
    "\n",
    "\n",
    "* Para un _a priori_ no informativo, asumimos que la probabilidad de ocurrencia de las clases es uniforme.\n",
    "$$\n",
    "\\hat{\\textsf{Pr}}(y) = \\frac{N_{y\\in\\mathbb{Y}}}{N}\n",
    "$$\n",
    "\n",
    "\n",
    "* Para la verosimilitud de ocurrencia de un atributo en una clase, obtenemos la frecuencia relativa de éste en las observaciones identificadas con la clase $y\\in\\mathbb{Y}$\n",
    "\n",
    "$$\n",
    "\\hat{\\textsf{Pr}}(X_{k} \\vert y) = \\frac{X_{yk}}{\\sum X_{yk}}\n",
    "$$\n",
    "\n",
    " Este tipo de modelo se conocen como __generativos__, dado que especifica un proceso aleatorio hipotético que genera las observaciones para cada clase. Este es el principal proceso en el entrenamiento del algoritmo.  Al algoritmo se le conoce como \"ingenuo\" dado que asume que todos los atributos $X_{1}, X_{2}, \\ldots, X_{k}$ son independientes entre sí, lo cual simplifica el proceso de entrenamiento al asumir que los atributos no se afectan mutuamente.\n",
    "\n",
    "\n",
    "Volviendo al ejemplo, al implementar el algoritmo sostenemos que condicional al estado de admitido/rechazado, el género y departamento del postulante son independientes entre sí. Este supuesto afirma que si algún postulante es hombre o mujer __no entrega información sobre el departamento que postuló__. \n",
    "\n",
    "# Ejemplo: Identificando la tasa de admitidos en UC-Berkeley\n",
    "\n",
    "Para este caso implementaremos un algoritmo NB Bernoulli para identificar los de admisión a la Universidad de California, Berkeley. Los datos provienen de la publicación _Bickel, P. J., Hammel, E. A., and O'Connell, J. W. (1975). Sex bias in graduate admissions: Data from Berkeley. Science, 187, 398–403. http://www.jstor.org/stable/1739581._ La base de datos se compone de 3 atributos: _Género_ del alumno prospectivo (2 categorías), _Departamento_ al cual postula (6 categorías que representa cada departamento) y Resultado de la _Admisión_ (2 categorías que representan si fue admitido o no).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# añadimos las librerías clásicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lec3_graphs as gfx\n",
    "# añadimos seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con nuestro ambiente de trabajo ya listo, vamos a importar `ucbaddmissions.csv` con `read_csv` y nos aseguraremos de eliminar la columna `Unnamed: 0` que se genera de forma automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admit</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>C</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Male</td>\n",
       "      <td>C</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Female</td>\n",
       "      <td>C</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Female</td>\n",
       "      <td>C</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>E</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Male</td>\n",
       "      <td>E</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Female</td>\n",
       "      <td>E</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Female</td>\n",
       "      <td>E</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Male</td>\n",
       "      <td>F</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Female</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>Female</td>\n",
       "      <td>F</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Admit  Gender Dept  Freq\n",
       "0   Admitted    Male    A   512\n",
       "1   Rejected    Male    A   313\n",
       "2   Admitted  Female    A    89\n",
       "3   Rejected  Female    A    19\n",
       "4   Admitted    Male    B   353\n",
       "5   Rejected    Male    B   207\n",
       "6   Admitted  Female    B    17\n",
       "7   Rejected  Female    B     8\n",
       "8   Admitted    Male    C   120\n",
       "9   Rejected    Male    C   205\n",
       "10  Admitted  Female    C   202\n",
       "11  Rejected  Female    C   391\n",
       "12  Admitted    Male    D   138\n",
       "13  Rejected    Male    D   279\n",
       "14  Admitted  Female    D   131\n",
       "15  Rejected  Female    D   244\n",
       "16  Admitted    Male    E    53\n",
       "17  Rejected    Male    E   138\n",
       "18  Admitted  Female    E    94\n",
       "19  Rejected  Female    E   299\n",
       "20  Admitted    Male    F    22\n",
       "21  Rejected    Male    F   351\n",
       "22  Admitted  Female    F    24\n",
       "23  Rejected  Female    F   317"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ucbadmissions.csv').drop(columns='Unnamed: 0')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer paso exploratorio, veamos cuál es la distribución de cada atributo en nuestra base. Un problema que encontraremos es que nuestro `DataFrame` es una tabla procesada que muestra la frecuencia de la combinación de valores en `'Admit'`, `'Gender'` y`'Dept'`. Esto nos generará problemas posteriormente cuando queramos implementar nuestro modelo, dado la baja cantidad de datos.\n",
    "Nuestra estrategia es aumentar artificalmente cada combinación de valores dado la frecuencia.\n",
    "\n",
    "Para ello implementaremos una función que tome como argumento de ingreso la tabla agregada, y devuelva la cantidad de observaciones correctas mediante `deaggregate_statistics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dado lo verboso de la función, ésta se encuentra en el archivo auxiliar\n",
    "df_deagg = gfx.deaggregate_statistics(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de seguir con nuestro análisis, debemos procurar que nuestra base desagregada represente la suma de `df['Freq']`. Esto lo logramos con una operación booleana simple. El resultado nos confiere que el procedimiento está bien hecho. Con nuestra base procesada, realizamos una serie de gráficos de barras por cada elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# devuelve un booleano que compare la cantidad de observaciones en ambas bases\n",
    "df_deagg.shape[0] == sum(df['Freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admit</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admitted</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Admit Gender Dept\n",
       "0  Admitted   Male    A\n",
       "1  Admitted   Male    A\n",
       "2  Admitted   Male    A\n",
       "3  Admitted   Male    A\n",
       "4  Admitted   Male    A"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deagg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos gráficar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# definimos un canvas con tamaños fijos para mejorar la presentación\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# para cada elemento de nuestra columna, devuelve un número (n) y el elemento (i)\n",
    "for n, i in enumerate(['Admit', 'Gender', 'Dept']):\n",
    "    # generamos tres subplots en una fila\n",
    "    plt.subplot(1, 3, n + 1)\n",
    "    # generamos un contador de frecuencia con seaborn\n",
    "    sns.countplot(y= df_deagg[i],\n",
    "                  # ordenamos las frecuencias de mayor a menor\n",
    "                  order = df_deagg[i].value_counts().index)\n",
    "    # agregamos el título\n",
    "    plt.title('Frecuencias para {}'.format(i))\n",
    "    # mejoramos los márgenes\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UC Berkeley es una universidad pública de elite, por lo que las tasas de rechazados no resultan sorprendentes. Aproximadamente el 61% de los postulantes fueron rechazados. La mayoría de los postulantes fueron a los departamentos A y C (ambos con un 20%), pero en general la postulación fue homogénea. La mayoría de los postulantes fueron hombres (cercano al 60%) y el restante fueron mujeres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected    0.61224\n",
      "Admitted    0.38776\n",
      "Name: Admit, dtype: float64 \n",
      "\n",
      "Male      0.594565\n",
      "Female    0.405435\n",
      "Name: Gender, dtype: float64 \n",
      "\n",
      "A    0.206142\n",
      "C    0.202828\n",
      "D    0.174989\n",
      "F    0.157755\n",
      "B    0.129253\n",
      "E    0.129032\n",
      "Name: Dept, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ , i in df_deagg.iteritems():\n",
    "    print(i.value_counts('%'),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deagg['Dept'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementado un algoritmo Naive Bayes\n",
    "\n",
    "Para implementar el modelo, utilizaremos la clase `BernoulliNB` dentro del módulo `linear_model` de la librería `sklearn`. Como el algoritmo NB es un problema de _clasificación supervisada_ dado que tenemos conocimiento sobre la cantidad de clases $y$ en un espacio finito $\\mathbb{Y}$, debemos importar de manera adicional las métricas de desempeño más comunes como `roc_auc_score`, `roc_curve`, `confusion_matrix`.\n",
    "\n",
    "Considerando que todos los registros en la base desagregada son strings, debemos transformar estos atributos categórico a numéricos para facilitarle el trabajo a `sklearn`. Para ello implementaremos la clase `LabelEncoder` que se encuentra en el módulo `preprocessing` de `sklearn`. Nuestro primer paso es convertir los atributos. `LabelEncoder` genera un encoding entre 0 y la cantidad de clases -1. Para generar nuestra recodificación, posterior a la inicialización de la clase `LabelEncoder` implementamos el método `fit_transform` que devuelve las etiquetas numéricas. El modelo que implementaremos sólo admite variables binarias, por lo que implementaremos el método `pd.get_dummies` para extraer una serie de binarias por cada categoría de departamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos los módulos de sklearn\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# instanciamos el objeto\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "# Implementamos el método fit_transform para actualizar y sobreescribir cada columna de atributos\n",
    "df_deagg['Gender'] = lbl.fit_transform(df_deagg['Gender'])\n",
    "df_deagg['Admit'] = lbl.fit_transform(df_deagg['Admit'])\n",
    "\n",
    "# generamos una serie de dummies en base a Dept y las concatenamos a nuestra base. \n",
    "# posteriormente, eliminamos la columna Dept\n",
    "df_deagg = pd.concat([df_deagg, pd.get_dummies(df_deagg['Dept'], prefix='dept')], axis=1).drop(columns='Dept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admit</th>\n",
       "      <th>Gender</th>\n",
       "      <th>dept_A</th>\n",
       "      <th>dept_B</th>\n",
       "      <th>dept_C</th>\n",
       "      <th>dept_D</th>\n",
       "      <th>dept_E</th>\n",
       "      <th>dept_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4525</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Admit  Gender  dept_A  dept_B  dept_C  dept_D  dept_E  dept_F\n",
       "4521      1       0       0       0       0       0       0       1\n",
       "4522      1       0       0       0       0       0       0       1\n",
       "4523      1       0       0       0       0       0       0       1\n",
       "4524      1       0       0       0       0       0       0       1\n",
       "4525      1       0       0       0       0       0       0       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solicitemos las últimas 5 observaciones de nuestra base\n",
    "df_deagg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.61224\n",
       "0    0.38776\n",
       "Name: Admit, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifiquemos que la variable Admit esta lista para ser procesada por el clasificador\n",
    "df_deagg['Admit'].value_counts('%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior a la reconversión de los valores, seguimos con nuestro flujo básico de trabajo generando muestras de entrenamiento y validación con `train_test_split`, dejando un 30% de la muestra como validación y declarando una semilla pseudoaleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_mat, X_test_mat, y_train_vec, y_test_vec = train_test_split(df_deagg.loc[:, 'Gender':'dept_F'],\n",
    "                                                                    df_deagg['Admit'],\n",
    "                                                                    test_size=.30,\n",
    "                                                                    random_state=11238)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El clasificador `BernoulliNB()`\n",
    "\n",
    "Siguiendo el flujo de trabajo, lo que debemos hacer es generar una instancia del Clasificador. La documentación de `BernoulliNB()` hace referencia a 4 hiperparámetros a considerar:\n",
    "1. `alpha`: Añade un parámetro aditivo a la probabilidad $\\hat{\\textsf{Pr}}(X_{k} \\vert y)$. Esta adición permite superar el problema del _floating point underflow_ cuando nos encontramos con probabilidades $\\hat{\\textsf{Pr}}(X_{k} \\vert y) = 0$. Cuando `alpha=1`, se llama suavización de Laplace y cuando `alpha` es un decimal entre 0 y 1 se conoce como suavización de Lidstone.\n",
    "- `binarize`: Implementado cuando los atributos son contínuos y se necesita declarar un umbral para la binarización.\n",
    "- `fit_prior`: Por defecto calcula la probabilidad _a priori_ de cada clase en la muestra de entrenamiento. Si es `False`, asume una distribución uniforme en base a $1/N_{y\\in\\mathbb{Y}}$.\n",
    "- `class_prior`: Permite ingresar la probabilidad _a priori_ para cada clase en el algoritmo de entrenamiento. Por defecto es `None`.\n",
    "\n",
    "Nuestro primer modelo tomará los argumentos por defecto de la clase. Partimos por instanciar un objeto y posteriormente implementar el método `.fit` donde ingresamos nuestra matriz de atributos (`X_train_mat`) y vector objetivo (`y_train_vec`). Python nos informa sobre los hiperparámetros especificados en la clase. Por defecto asume una suavización con un `alpha=1` y sin un umbral de binarización declarado, dado que nuestros atributos ya están binarizados de forma previa. Para este modelo inicial no añadiremos información _a priori_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier = BernoulliNB()\n",
    "nb_classifier.fit(X_train_mat, y_train_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizado el `fit` de nuestro modelo, el siguiente paso es realizar las predicciones. Siguiendo el flujo clásico del aprendizaje de máquinas, debemos ingresar la matriz de atributos reservada para validación. Como todo modelo de clasificación implementado de `sklearn`, podemos extraer tres predicciones a partir de nuestro modelo entrenado. \n",
    "\n",
    "#### El logaritmo de la probabilidad\n",
    "\n",
    "La primera opción es extraer el logaritmo de la probabilidad con `predict_log_proba` para cada una de las clases $y \\in \\mathbb{Y}$. Este es el resultado directo de resolver $\\underset{y\\in\\mathbb{Y}}{\\textsf{argmax}}$. Si ingresamos nuestra matriz de validación y solicitamos por el logaritmo de la probabilidad para cada una de las clases estimadas. En este ejemplo deseamos saber cuáles son los valores para la primera observación. Observamos que la clase 0 tiene un menor logaritmo de la probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.46562497, -0.9881699 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_log_prob_pred = nb_classifier.predict_log_proba(X_test_mat)\n",
    "nb_log_prob_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La probabilidad\n",
    "\n",
    "El problema del logaritmo de la probabilidad es que es intuitivo para el computador (porque evita trabajar con productorias), pero poco intuitivo para el ser humano. Resulta que si exponenciamos cada uno de los elementos, obtendremos la probabilidad de pertenencia a cada clase mediante el método `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62774266, 0.37225734])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_prob_pred = nb_classifier.predict_proba(X_test_mat)\n",
    "nb_prob_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como toda probabilidad, la suma de todos los eventos debe ser 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(nb_prob_pred[0]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asegurarnos que la exponenciación de `nb_log_prob_pred` sea igual a los resultados entregados por `nb_prob_pred` podemos ejecutar una expresión booleana preguntando si los valores de ambos objetos son iguales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_prob_pred[0] == np.exp(nb_log_prob_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La clase asignada siguiendo el principio máximo _a posteriori_ de la probabilidad\n",
    "\n",
    "Finalmente, se asigna la clase en base a la maximización del estimado _a posteriori_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_class_pred = nb_classifier.predict(X_test_mat)\n",
    "nb_class_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de desempeño en el algoritmo NB\n",
    "\n",
    "Dado que el problema que busca resolver el algoritmo es el de asignar alguna clase en un espacio finito a una observación específica, implementamos una estrategia supervisada donde analizamos el desempeño del algoritmo en clasificar de manera adecuada los casos correctamente predichos. Esto lo logramos mediante el contraste entre las predicciones en nuestra muestra de validación y las clases verdaderas. \n",
    "\n",
    "El primer elemento lo logramos mediante una matriz de confusión, que permite contrastar las clases verdaderas con el pronóstico del modelo. Mediante este cruce extraemos información sobre la tasa de verdaderos (Clasificaciones correctamente predichas) y falsos (Clasificaciones incorrectas).\n",
    "\n",
    "Para implementar una matriz de confusión importamos el método `confusion_matrix` del módulo `metrics` de la librería `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11420a390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# en base a un vector de clases predichas\n",
    "y_hat = nb_classifier.predict(X_test_mat)\n",
    "# generar una matriz confusa donde el primer argumento es el vector de prueba\n",
    "# y el segundo es el vector de clases predichas.\n",
    "# el resultado lo dividimos por el largo del vector de prueba\n",
    "# para obtener un porcentaje por sobre la cantidad de casos\n",
    "cnf = confusion_matrix(y_test_vec, y_hat)/len(y_test_vec)\n",
    "\n",
    "# guardamos las etiquetas de las clases\n",
    "target_label = ['Admitted', 'Rejected']\n",
    "\n",
    "# Implementamos un mapa de calor definiendo las clases\n",
    "sns.heatmap(cnf, xticklabels=target_label,\n",
    "            yticklabels=target_label,\n",
    "            # generamos las anotaciones en términos porcentuales\n",
    "            annot=True, fmt=\".1%\", \n",
    "            # evitamos la barra y cambiamos el colormap\n",
    "            cbar=False, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo clasifica de forma correcta aproximadamente el 70% de los casos como positivos o negativos. El modelo tiende a desempeñarse de peor manera para predicir los casos aceptados, en comparación a los casos rechazados.\n",
    "\n",
    "Otra manera de observar esto es mediante la obtención de métricas de desempeño como el `classification_report`, que entrega la precisión (Porcentaje de identificaciones positivas correctas por sobre el total de predicciones como positivas), el recall (Porcentaje de identificaciones positivas por sobre el total de predicciones correctas) y el F1 (Media armónica entre Precision y Recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.58       533\n",
      "           1       0.73      0.79      0.76       825\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      1358\n",
      "   macro avg       0.68      0.67      0.67      1358\n",
      "weighted avg       0.69      0.69      0.69      1358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# generar un reporte de métricas de precisión, recall y f1\n",
    "print(classification_report(y_test_vec, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas reportadas apoyan el diagnóstico realizado con la matriz de confusión. El modelo tiene un mejor desempeño para predicir correctamente los rechazados por sobre los aceptados. Las métricas tienen valores más altos para los casos clasificados como rechazados. Para todas las métricas, los puntajes son mayores que en comparación al promedio global de la muestra.\n",
    "\n",
    "Por último, siempre es bueno graficar el rango de errores con el cual opera nuestro modelo. Para ello implementamos la curva ROC (Receiving Operating Characteristics), que evalúa la relación entre falsos positivos (cuando el modelo etiqueta erróneamente) y falsos negativos (cuando el modelo ignora etiquetas). También solicitaremos el área bajo la curva ROC.\n",
    "\n",
    "Para implementarlo ocupamos los métodos `roc_curve` y `roc_auc_score` del módulo `metrics` de la librería `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11427ab00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# para implementar el área bajo la curva necesitamos el puntaje\n",
    "# de probabilidad, no la clase predicha. Para ello implementamos predict_proba\n",
    "y_hat_pr = nb_classifier.predict_proba(X_test_mat)[:,1]\n",
    "\n",
    "# el método roc_curve devuelve 3 elementos: falsos positivos, verdaderos positivos,\n",
    "# y threshold. Este último lo podemos ignorar con _\n",
    "fpr, tpr, _ = roc_curve(y_test_vec, y_hat_pr)\n",
    "\n",
    "# podemos obtener el área bajo la curva roc con roc_auc_score\n",
    "auc = round(roc_auc_score(y_test_vec, y_hat_pr), 3)\n",
    "\n",
    "# graficamos\n",
    "plt.plot(fpr, tpr, label=\"AUC = {}\".format(auc), color='tomato', lw=4)\n",
    "plt.xlabel('False Positive')\n",
    "plt.ylabel('True Positive')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "# graficamos el clasificador por chance.\n",
    "plt.plot([0, 1], [0, 1], color='slategrey')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar la idoneidad de nuestro modelo y su capacidad predictiva, necesitamos generar un benchmark analítico, que generalmente se traduce en un clasificador correcto por chance. Éste toma la forma matemática de $1/\\mathbb{Y}$.\n",
    "\n",
    "En este caso estamos trabajando con dos clases, por lo que la probabilidad de tener una clasificación correcta dado que la etiquetamos al azar es del 50%. Nuestros modelos deben superar este benchmark para considerarlos eficientes. En este caso, nuestro modelo tiene un desempeño un 20% superior a clasificar correctamente al azar una observación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efecto de la probabilidad a priori en el modelo\n",
    "\n",
    "Un aspecto a considerar en el algoritmo NB (y de manera más general en el marco analítico Bayesiano), es la ventaja de poder ingresar información previa sobre cómo se comportan nuestras clases. Esta información conocida como probabilidad _a priori_, interactúa con la verosimilitud del evento para actualizarlo en función del comportamiento pasado.\n",
    "\n",
    "Por defecto, `BernoulliNB` infiere las clases _a priori_ a partir de la frecuencia empírica de ocurrencia de estas. Una vez inicializado nuestro modelo podemos ingresar al logaritmo de la probabilidad con `BernoulliNB().class_log_prior_`. Exponenciando este array obtenemos la probabilidad _a priori_ de ocurrencia de cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39, 0.61])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(nb_classifier.class_log_prior_).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos asegurarnos que el modelo aprenderá la información _a priori_ a partir de la frecuencia de ocurrencia del vector objetivo, de manera tal de no intervenir el modelo. Si solicitamos el value counts de nuestro vector objetivo __antes de ser segmentado__ obtendremos resultados similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.61\n",
       "0    0.39\n",
       "Name: Admit, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deagg['Admit'].value_counts('%').round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora generaremos un experimiento donde someteremos nuestro algoritmo clasificador a distintas especificaciones sobre la ocurrencia previa de las clases. En la función `compare_priors` comparamos las métricas Accuracy, Recall, Precision, F1 y AUC para las siguientes especificaciones, dado los priors y las muestras de entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 1: a priori no informativo\n",
    "\n",
    "En este caso las métricas son idénticas a las reportadas en el modelo, puesto que por defecto infiere la frecuencia de cada clase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A priori: [0.39, 0.61]\n",
      "Accuracy: 0.694\n",
      "Recall: 0.79\n",
      "Precision: 0.729\n",
      "F1: 0.759\n",
      "AUC: 0.708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gfx.compare_priors(X_train=X_train_mat,\n",
    "                   X_test=X_test_mat,\n",
    "                   y_train=y_train_vec,\n",
    "                   y_test=y_test_vec,\n",
    "                   prior=[0.39, 0.61])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 2: A priori, clases extremadamente balanceadas\n",
    "\n",
    "Al asumir que ambas clases tienen iguales chances de ocurrir. En este escenario hay un empeoramiento general del modelo, ya que hay una disminución en el desempeño de las métricas. El modelo asume en base a la información previa que como antes habían más postulantes aceptados y menos rechazados, la verosimilitud tiende a incorporar ésta información conllevando a una pérdida en la tasa general de clasificaciones correctas (Accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A priori: [0.5, 0.5]\n",
      "Accuracy: 0.672\n",
      "Recall: 0.713\n",
      "Precision: 0.738\n",
      "F1: 0.725\n",
      "AUC: 0.708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gfx.compare_priors(X_train=X_train_mat,\n",
    "                   X_test=X_test_mat,\n",
    "                   y_train=y_train_vec,\n",
    "                   y_test=y_test_vec,\n",
    "                   prior=[.5, .5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 3: Clases desbalanceadas. 4 de 5 entran\n",
    "\n",
    "En este caso se encuentra una mayor precisión en el modelo, lo que significa que identifica bien quienes están clasificados como rechazados entre los correctamente clasificados. Esto se debe a que estamos aumentando de manera substancial el efecto de la información a priori en los aceptados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A priori: [0.8, 0.2]\n",
      "Accuracy: 0.513\n",
      "Recall: 0.216\n",
      "Precision: 0.927\n",
      "F1: 0.35\n",
      "AUC: 0.708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gfx.compare_priors(X_train=X_train_mat,\n",
    "                   X_test=X_test_mat,\n",
    "                   y_train=y_train_vec,\n",
    "                   y_test=y_test_vec,\n",
    "                   prior=[.8, .2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 4: Berkeley en el 2015\n",
    "\n",
    "Podemos actualizar nuestro algoritmo para ver cómo se comportarían ésta muestra en base a los últimos datos disponibles sobre las tasas de aceptación. La información disponible en el sitio web de Berkeley (https://admissions.berkeley.edu/student-profile) sugiere que aproximadamente un 17% de los postulantes son aceptados, con un 83% rechazados. ¿Cómo se comportaría nuestra predicción en base a esta información?\n",
    "\n",
    "Resulta que al implementar priors correspondientes al 2015, nuestro modelo mejora en su puntaje F1, así como en el Recall, por lo que nuestro modelo mejora en la capacidad de predecir correctamente tanto positivos como negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A priori: [0.17, 0.83]\n",
      "Accuracy: 0.643\n",
      "Recall: 0.872\n",
      "Precision: 0.655\n",
      "F1: 0.748\n",
      "AUC: 0.708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gfx.compare_priors(X_train=X_train_mat,\n",
    "                   X_test=X_test_mat,\n",
    "                   y_train=y_train_vec,\n",
    "                   y_test=y_test_vec,\n",
    "                   prior=[.17, .83])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspectos Adicionales\n",
    "\n",
    "A nivel de módulo, `sklearn.naive_bayes` también presenta variantes del algoritmo ingenuo para casos donde nuestro vector objetivo tiene más de 2 clases posibles (conocido como el Multinoulli Naive Bayes) y una variante donde nuestros atributos son contínuos y podemos implementar una distribución Gaussiana para aproximarnos a las clases (conocido como el Gaussian Naive Bayes). \n",
    "\n",
    "\n",
    "* `MultinomialNB`: Puede ser implementado cuando deseamos realizar un modelo predictivo con $\\mathbb{Y} \\geq 2$ y podemos aproximarnos mediante la distribución Multinoulli con forma\n",
    "\n",
    "$$\n",
    "\\textsf{Pr}(X \\vert y) = \\prod_{i\\leq k \\leq n_{d}} \\textsf{Cat}(X_{k} \\vert \\boldsymbol{\\mu}_{yk})\n",
    "$$\n",
    "\n",
    "donde $\\boldsymbol{\\mu}_{yk}$  es una mezcla de valores posibles $\\forall y \\in \\mathbb{Y}$. Al instanciar un objeto con esta clase, los hiperparámetros a considerar son los mismos que en el `BernoulliNB`.\n",
    "\n",
    "\n",
    "\n",
    "* `GaussianNB`: Lo podemos implementar cuando los atributos son contínuos y podemos implementar la distribución Gaussiana para aproximarnos a las clases con forma\n",
    "\n",
    "$$\n",
    "\\textsf{Pr}(X \\vert y) = \\prod_{i\\leq k \\leq n_{d}} \\textsf{Normal}(X_{k} \\vert \\mu_{yk}, \\sigma^{2}_{yk})\n",
    "$$\n",
    "\n",
    "donde $\\mu_yk$ es la media del atributo $k$ en la clase $y$, y $\\sigma^{2}_{yk}$ es su varianza. Al instanciar un objeto con esta clase, los hiperparámetros a considerar son las probabilidades _a priori_. En caso de desear mayor estabilidad de los cálculos, se puede alterar `var_smoothing` para modificar la porción de la varianza conjunta de los atributos que se asigna a la varianza individual.\n",
    "\n",
    "\n",
    "### Pros y Cons\n",
    "\n",
    "\n",
    "El algoritmo bayesiano ingenuo presenta una serie de virtudes:\n",
    "* Es intuitivo en términos conceptuales, porque buscamos encontrar la clase más probable de una observación teniendo en cuenta la probabilidad de ocurrencia de un atributo específico en una clase.\n",
    "* Su complejidad algorítmica es $\\mathcal{O}(ND)$ donde $N$ es la cantidad de clases y $D$ la cantidad de atributos, lo cual lo hace relativamente rápido e inmune a _overfitting_ (Murphy, 2013. pp. 82).\n",
    "* Suele desempeñarse bien, independiente del problema. Esto lo transforma en uno de los primeros modelos generativos que se puede implementar para analizar un problema de clasificación.\n",
    "* Su baja complejidad algorítmica facilita la inclusíón de grandes cantidades de atributos.\n",
    "* Dado que es un modelo generativo, maneja de mejor manera los datos perdidos.\n",
    "* Además, también debido a que es generativo, permite simular data sintética, lo que es útil para realizar data augmentation o simular fenómenos.\n",
    "\n",
    "Algunas de sus desventajas:\n",
    "\n",
    "* Su nombre lo dice todo: Es un algoritmo ingenuo que descansa en el supuesto que todos los atributos son independientes entre sí, condicional a la clase. Esto suele generar situaciones donde hay baja varianza y alto sesgo (Hand y Yu, 2010).\n",
    "\n",
    "\n",
    "# Referencias\n",
    "\n",
    "* Hand, D, J y Yu, K. 2010. Idiot's Bayes: Not So Stupid After All?. International Statistical Review. 69(3).\n",
    "* Stone, K. 2013. Bayes Rule: A tutorial introduction to Bayesian Analysis. Sebtel Press. Ch: 1 An Introduction to Bayes Rule.\n",
    "* Manning, C; Schütze, H. 1999. Foundations of Statistical Natural Language Processing. Cambridge, MA: Massachusetts Institute of Technology. Ch7: Word Sense Disambiguation.\n",
    "* Hastie, T; Tibshirani, T; Friedman, J. 2008. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer Series in Statistics. Springer. Ch6: Kernel Smoothing Methods.\n",
    "* Ng, A; Jordan, M. 2001. On Discriminative vs. Generative classifier: A comparison of logistic regression and naïve Bayes.\n",
    "* McElreath, R. 2016. Statistical Rethinking. A Bayesian Course with Examples in R and Stan. Ch. 3: Sampling the Imaginary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
